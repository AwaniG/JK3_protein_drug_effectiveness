{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1Iud18e0ct5gFBwxtOB45ES9ARCFk4Wtd","timestamp":1698901903194}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"xonBvq1DPJd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"h3NnUBXeOnP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --pre deepchem\n","import deepchem\n","deepchem.__version__"],"metadata":{"id":"F74OkxNFOxqa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n","# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n","!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n","if not 'bertviz_repo' in sys.path:\n","  sys.path += ['bertviz_repo']\n","!pip install regex"],"metadata":{"id":"DSykQCu7O4PP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","dataset = pd.read_csv('/content/drive/Shareddrives/1:1 Awani Gadre/Dataset/JAK3_processed_PIC50.csv')\n","dataset.head()"],"metadata":{"id":"QlwtcXgfPNY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiZWWNPdOaMT"},"outputs":[],"source":["from transformers import AutoModelForMaskedLM, AutoTokenizer, pipeline, RobertaModel, RobertaTokenizer\n","from bertviz import head_view\n","\n","model = AutoModelForMaskedLM.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\")\n","tokenizer = AutoTokenizer.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\")\n","\n","fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n","# Create a new DataFrame to store the tokenized vectors\n","tokenized_vector_df = pd.DataFrame()\n","\n","for index in range(0, len(dataset)):\n","    smiles = dataset['canonical_smiles'].iloc[index]\n","    # Tokenize the SMILES string\n","    input_ids = tokenizer.encode(smiles, return_tensors=\"pt\").tolist()[0]\n","    # Ensure the list has length 95 by padding with zeros\n","    input_ids.extend([0] * (95 - len(input_ids)))\n","    # Add to DataFrame\n","    tokenized_vector_df = tokenized_vector_df.append(pd.Series(input_ids), ignore_index=True)\n","\n","# Concatenate the new DataFrame with the existing dataset along the columns\n","dataset = pd.concat([dataset, tokenized_vector_df], axis=1)\n","\n","# Save the updated DataFrame as a new CSV file\n","dataset.to_csv('/content/drive/Shareddrives/1:1 Awani Gadre/Dataset/JAK3_processed_PIC50_with_chembert_tokenized.csv', index=False)\n"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming X is your features and y is your labels\n","train_df, valid_test_df = train_test_split(dataset, test_size=0.30, random_state=42)\n","test_df, valid_df = train_test_split(valid_test_df, test_size=0.50, random_state=42)"],"metadata":{"id":"awGRr65KRTHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df"],"metadata":{"id":"AWYQV0iPRgJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","# Initialize and train regressor\n","regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n","regressor.fit(train_df.iloc[:,2:], train_df.iloc[:,1])"],"metadata":{"id":"4rNr9KiARAi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict\n","y_pred = regressor.predict(test_df.iloc[:,2:])\n","\n","# Calculate metrics\n","rmse = np.sqrt(mean_squared_error(test_df.iloc[:,1], y_pred))\n","mae = mean_absolute_error(test_df.iloc[:,1], y_pred)\n","r2 = r2_score(test_df.iloc[:,1], y_pred)\n","mape = np.mean(np.abs((test_df.iloc[:,1] - y_pred) / test_df.iloc[:,1])) * 100\n","\n","# Print metrics\n","print(f\"RMSE: {rmse}\")\n","print(f\"MAE: {mae}\")\n","print(f\"R^2: {r2}\")\n","print(f\"MAPE: {mape}%\")"],"metadata":{"id":"yEK0NAYUSEgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.max(dataset['pIC50'])"],"metadata":{"id":"3JeHYje9Smd1"},"execution_count":null,"outputs":[]}]}